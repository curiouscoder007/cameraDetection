{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Deeplearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgphFZ7dyHXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import imageio\n",
        "#tf.enable_eager_execution()\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMIe_P5xyVgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8af11567-1a86-40b5-f0ac-092c4f6b6726"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERV8RZX_0bFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#path=os.getcwd()+'/drive/My Drive/Colab Notebooks/sp-society-camera-model-identification'\n",
        "#print(path)\n",
        "path = '/content/drive/My Drive/Colab Notebooks/sp-society-camera-model-identification'\n",
        "os.chdir(path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8VYXBnAyHXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ef43e12a-bbdc-42cc-97da-c5292a44a5dc"
      },
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4LAmH2yHXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a3614d30-83d1-455b-f389-5d28454c1e49"
      },
      "source": [
        "trainpath = path+\"/train\"\n",
        "os.chdir(trainpath)\n",
        "\n",
        "df1 = pd.read_pickle('train_images1.pkl')\n",
        "df1.head(5)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.47058824, shape=(), dtype=float...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.6745098, shape=(), dtype=float3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.59607846, shape=(), dtype=float...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.41568628, shape=(), dtype=float...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.5764706, shape=(), dtype=float3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            location                                              image\n",
              "0  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  (((tf.Tensor(0.47058824, shape=(), dtype=float...\n",
              "1  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  (((tf.Tensor(0.6745098, shape=(), dtype=float3...\n",
              "2  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  (((tf.Tensor(0.59607846, shape=(), dtype=float...\n",
              "3  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  (((tf.Tensor(0.41568628, shape=(), dtype=float...\n",
              "4  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  (((tf.Tensor(0.5764706, shape=(), dtype=float3..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGhMPO7fyHXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c59a4dfa-08a3-417d-9c67-8491b00c8f00"
      },
      "source": [
        "df1.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1375, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK19soFAyHXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e81806b-51f8-47b8-ae92-9404cc4db7ab"
      },
      "source": [
        "df2 = pd.read_pickle('train_images2.pkl')\n",
        "df2.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1375, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBJcL4ucyHXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ce8d218-e4ad-4a78-b931-70aa2adc6a88"
      },
      "source": [
        "\n",
        "df1 = pd.concat([df1,df2])\n",
        "df1.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2750, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXLjW8cmyHXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ec5a3c6e-5c94-4b33-f833-60977ae3ac92"
      },
      "source": [
        "df1['camera'] = df1['location'].apply(lambda x: x.split('\\\\')[-2])\n",
        "df1.head()    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>image</th>\n",
              "      <th>camera</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.47058824, shape=(), dtype=float...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.6745098, shape=(), dtype=float3...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.59607846, shape=(), dtype=float...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.41568628, shape=(), dtype=float...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.5764706, shape=(), dtype=float3...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            location  ...    camera\n",
              "0  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...  HTC-1-M7\n",
              "1  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...  HTC-1-M7\n",
              "2  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...  HTC-1-M7\n",
              "3  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...  HTC-1-M7\n",
              "4  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...  HTC-1-M7\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnUY3WfYyHXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "txt= '''cameras = os.listdir()\n",
        "cameras.remove('.gitignore')\n",
        "cameras.remove('train_images1.pkl')\n",
        "cameras.remove('train_images2.pkl')\n",
        "cameras.remove('model_weights.h5')\n",
        "filecount = [len(os.listdir(camera))  for camera in cameras]\n",
        "cam = pd.DataFrame({'camera_type':cameras,'filecount':filecount})\n",
        "\n",
        "class_dict = {}\n",
        "for id in cam.index:\n",
        "    class_dict.update({cam.loc[id,'camera_type']:id})\n",
        "'''    \n",
        "class_dict = {'HTC-1-M7': 0,\n",
        " 'iPhone-4s': 1,\n",
        " 'iPhone-6': 2,\n",
        " 'LG-Nexus-5x': 3,\n",
        " 'Motorola-Droid-Maxx': 4,\n",
        " 'Motorola-Nexus-6': 5,\n",
        " 'Motorola-X': 6,\n",
        " 'Samsung-Galaxy-Note3': 7,\n",
        " 'Samsung-Galaxy-S4': 8,\n",
        " 'Sony-NEX-7': 9}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUAZtJ4ZyHXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "9e374d87-7e1e-4ded-88b2-a53f9249848f"
      },
      "source": [
        "df1['class'] = df1['camera'].apply(lambda x:class_dict[x])\n",
        "df1.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>image</th>\n",
              "      <th>camera</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.47058824, shape=(), dtype=float...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.6745098, shape=(), dtype=float3...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.59607846, shape=(), dtype=float...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.41568628, shape=(), dtype=float...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
              "      <td>(((tf.Tensor(0.5764706, shape=(), dtype=float3...</td>\n",
              "      <td>HTC-1-M7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            location  ... class\n",
              "0  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...     0\n",
              "1  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...     0\n",
              "2  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...     0\n",
              "3  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...     0\n",
              "4  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...  ...     0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtfvuifVyHXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1['image_array'] = df1['image'].apply(lambda x:x.numpy())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya61PisHyHXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting training and test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(df1['image_array'], df1['class'].values,test_size=.33, random_state=42)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om9d01qtyHXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWI5NHXNyHXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "def reshape_input(Xtrain):\n",
        "    #Xtrain = np.stack(Xtrain.values) #convert a pandas series of arrays into one single array\n",
        "    input_cols = Xtrain.shape[1]*Xtrain.shape[2]*Xtrain.shape[3]\n",
        "    Xtrain = np.reshape(Xtrain,(Xtrain.shape[0],input_cols)) #flatten the data to single set of neurons\n",
        "    return Xtrain"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTDhbHO9yHXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_input_cnn(Xtrain):\n",
        "    Xtrain = np.stack(Xtrain.values) #convert a pandas series of arrays into one single array\n",
        "    return Xtrain"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWnFlm9jDj70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M0K9kjbyHXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9710f92-91c3-4591-fc41-8e87a5eedbab"
      },
      "source": [
        "#categorize output data. \n",
        "import keras\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "def reshape_target(Ytrain):\n",
        "    Ytrain = to_categorical(Ytrain,num_classes=10)\n",
        "    return Ytrain\n",
        "\n",
        "#Ytrain = reshape_target(Ytrain)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMy4X1UyyHXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTmzc3ZAyHXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeT8tLkoNaFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bd2d948-e40c-4ad9-879d-5f9b0e57706f"
      },
      "source": [
        "Xtrain.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1842,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4HVdEQbyHXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(Xtrain,Ytrain,output_units=500):\n",
        "    model = Sequential()\n",
        "    input_cols = Xtrain.shape[1]\n",
        "    model.add(Dense(output_units, activation='relu',input_shape=(input_cols,)))\n",
        "    model.add(Dense(output_units))\n",
        "    model.add(Dense(output_units))\n",
        "    model.add(Dense(output_units))\n",
        "    #model.add(Dense(output_units))\n",
        "    #model.add(Dense(output_units))\n",
        "    model.add(Dense(10,activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpC6-avb3Hu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "def get_cnnmodel(X,Y):\n",
        "  model=Sequential()\n",
        "  \n",
        "  shape = Xtrain[0].shape\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='relu',input_shape=shape))\n",
        "  model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "  model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWvwYG7KUPn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this function is used to modify the generator's output to suit NN's need instead of a CNN\n",
        "def datagen_modifier(X, Y,batchsize):\n",
        "  datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True)\n",
        "  while True:\n",
        "    for batch in datagen.flow(np.stack(X.values),Y,batch_size= batchsize):\n",
        "      batch_x = reshape_input(batch[0])\n",
        "      batch_y = reshape_target(batch[1])\n",
        "      yield (batch_x,batch_y)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0iIZ19hIVAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain = reshape_input_cnn(Xtrain)\n",
        "Ytrain = reshape_target(Ytrain)\n",
        "#split the training dataset into validation set as well \n",
        "xtrain, xval, ytrain, yval = train_test_split(Xtrain, Ytrain,test_size=.2, random_state=42)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBNH6UlwyHX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing a normal neural network\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "def trainModel(xtrain,ytrain,xval,yval,epochs):\n",
        "  earlystopping_monitor = EarlyStopping(monitor='val_accuracy',min_delta=.1,patience=10,verbose=1)\n",
        "  datagen = ImageDataGenerator(\n",
        "      featurewise_center=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True)\n",
        "  #create validation split for the fit_generator\n",
        "  #datagen.fit() no need to fit as the featurewise_center is set to false.\n",
        "\n",
        "  trainingsize = 6400 #keep the number as a multiple of batchsize to get same number of images each time\n",
        "  batchsize = 64\n",
        "  iteration = 1\n",
        "  itersize = trainingsize//batchsize\n",
        "  model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "      filepath='model_weights_cnn_v2.h5',\n",
        "      save_weights_only=True,\n",
        "      monitor='accuracy',\n",
        "      mode='max',\n",
        "      save_best_only=True)\n",
        "  #batch_x = np.full((64,192*192*3),1) used for the NN\n",
        "  model = get_cnnmodel(xtrain,ytrain)\n",
        "  optimizer = Adam(0.001)#default learning rate is .001\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.load_weights('model_weights_cnn_v2.h5')\n",
        "  model.fit_generator(datagen.flow(xtrain,ytrain,batchsize), steps_per_epoch=5120, epochs=epochs, \n",
        "                      validation_data=datagen.flow(xval,yval,batchsize),validation_steps= 1280,verbose=1,callbacks=[model_checkpoint_callback]) \n",
        "  #model.fit(xtrain,ytrain,validation_split=.3,epochs=40,callbacks=[earlystopping_monitor])\n",
        "  model.save('cnn_model_v2.h5')\n",
        "  return model\n",
        "\n",
        "#lr = [0.0001]\n",
        "#changing the lr from .001 to .0001 to increase accuracy more than 32\n",
        "#model.save_weights('model_weights.h5')\n",
        "#using lr of .001 has the best improvement in accuracy so far(.17 to .48 over 10 epoches) So, going lesser than that and increaseing the epoches to 25\n",
        "#.00001 is slow as it increases accuracy from.10 to .27 in 25 epoches\n",
        "#.0001 .13->.46 in 25 epoches (caused resouorceexhaustedError) \n",
        "#.001 .17 -> .72 (it fluctuates after .71, maxes at .72 and decreases again). \n",
        "#Increasing the output units to 1000 to see the increase, with lr of .001. Accuracy reaches upto .76 but its not converging. \n",
        "#WOULD REDUCING LEARNING RATE AFTER 20 EPOCHES HELP TO CONVEREGE?\n",
        "#validation accuracy is still at .28 max\n",
        "\n",
        "#to use Model checkpoint, refer link here: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
        "#preprocessing and training\n",
        "#training->hyperparameter\n",
        "#preprocessing -> rotate imags and others"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9OKY3rutftC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "63a00ae9-8091-4ca0-e476-ffeef3e1a552"
      },
      "source": [
        "model = trainModel(xtrain,ytrain,xval,yval,epochs=1)\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "5120/5120 [==============================] - 3931s 768ms/step - loss: 0.1750 - accuracy: 0.9495 - val_loss: 3.4287 - val_accuracy: 0.7733\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 190, 190, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 188, 188, 32)      18464     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 186, 186, 32)      9248      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1107072)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                11070730  \n",
            "=================================================================\n",
            "Total params: 11,100,234\n",
            "Trainable params: 11,100,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I6ie8TQyS0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "def testModel(xtest,ytest):\n",
        "  model = keras.models.load_model('cnn_model_v2.h5')\n",
        "  y_pred = model.predict(xtest)\n",
        "  #print(y_pred)\n",
        "  y_pred = [np.argmax(y) for y in y_pred] \n",
        "  score = accuracy_score(ytest,y_pred)\n",
        "  report = classification_report(ytest,y_pred)\n",
        "  return score,report\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-_lryQYWYEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "d3251ce0-0aa4-4a41-bd04-277db6764147"
      },
      "source": [
        "xtest = reshape_input_cnn(Xtest)\n",
        "score,report = testModel(xtest,Ytest)\n",
        "print('Accuracy score:'+str(score))\n",
        "print(report)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:0.7389867841409692\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77        89\n",
            "           1       0.76      0.90      0.82       101\n",
            "           2       0.85      0.51      0.64        86\n",
            "           3       0.76      0.81      0.78        88\n",
            "           4       0.86      0.68      0.76        90\n",
            "           5       0.60      0.87      0.71       100\n",
            "           6       0.66      0.74      0.69        91\n",
            "           7       0.76      0.64      0.70        89\n",
            "           8       0.69      0.87      0.77        97\n",
            "           9       0.89      0.61      0.72        77\n",
            "\n",
            "    accuracy                           0.74       908\n",
            "   macro avg       0.77      0.73      0.74       908\n",
            "weighted avg       0.76      0.74      0.74       908\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}