{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import imageio\n",
    "#tf.enable_eager_execution()\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path=os.getcwd()+'\\\\\\sp-society-camera-model-identification'\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.47058824, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.6745098, shape=(), dtype=float3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.59607846, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.41568628, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.5764706, shape=(), dtype=float3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            location  \\\n",
       "0  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "1  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "2  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "3  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "4  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "\n",
       "                                               image  \n",
       "0  (((tf.Tensor(0.47058824, shape=(), dtype=float...  \n",
       "1  (((tf.Tensor(0.6745098, shape=(), dtype=float3...  \n",
       "2  (((tf.Tensor(0.59607846, shape=(), dtype=float...  \n",
       "3  (((tf.Tensor(0.41568628, shape=(), dtype=float...  \n",
       "4  (((tf.Tensor(0.5764706, shape=(), dtype=float3...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainpath = path+\"\\\\train\"\n",
    "os.chdir(trainpath)\n",
    "\n",
    "df1 = pd.read_pickle('train_images1.pkl')\n",
    "df1.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_pickle('train_images2.pkl')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2750, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1 = pd.concat([df1,df2])\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>image</th>\n",
       "      <th>camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.47058824, shape=(), dtype=float...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.6745098, shape=(), dtype=float3...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.59607846, shape=(), dtype=float...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.41568628, shape=(), dtype=float...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.5764706, shape=(), dtype=float3...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            location  \\\n",
       "0  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "1  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "2  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "3  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "4  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "\n",
       "                                               image    camera  \n",
       "0  (((tf.Tensor(0.47058824, shape=(), dtype=float...  HTC-1-M7  \n",
       "1  (((tf.Tensor(0.6745098, shape=(), dtype=float3...  HTC-1-M7  \n",
       "2  (((tf.Tensor(0.59607846, shape=(), dtype=float...  HTC-1-M7  \n",
       "3  (((tf.Tensor(0.41568628, shape=(), dtype=float...  HTC-1-M7  \n",
       "4  (((tf.Tensor(0.5764706, shape=(), dtype=float3...  HTC-1-M7  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['camera'] = df1['location'].apply(lambda x: x.split('\\\\')[-2])\n",
    "df1.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HTC-1-M7': 0,\n",
       " 'iPhone-4s': 1,\n",
       " 'iPhone-6': 2,\n",
       " 'LG-Nexus-5x': 3,\n",
       " 'Motorola-Droid-Maxx': 4,\n",
       " 'Motorola-Nexus-6': 5,\n",
       " 'Motorola-X': 6,\n",
       " 'Samsung-Galaxy-Note3': 7,\n",
       " 'Samsung-Galaxy-S4': 8,\n",
       " 'Sony-NEX-7': 9}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cameras = os.listdir()\n",
    "cameras.remove('.gitignore')\n",
    "cameras.remove('train_images1.pkl')\n",
    "cameras.remove('train_images2.pkl')\n",
    "cameras.remove('model_weights.h5')\n",
    "filecount = [len(os.listdir(camera))  for camera in cameras]\n",
    "cam = pd.DataFrame({'camera_type':cameras,'filecount':filecount})\n",
    "\n",
    "class_dict = {}\n",
    "for id in cam.index:\n",
    "    class_dict.update({cam.loc[id,'camera_type']:id})\n",
    "    \n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>image</th>\n",
       "      <th>camera</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.47058824, shape=(), dtype=float...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.6745098, shape=(), dtype=float3...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.59607846, shape=(), dtype=float...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.41568628, shape=(), dtype=float...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Study\\Capstone\\cameraDetection\\sp-society-c...</td>\n",
       "      <td>(((tf.Tensor(0.5764706, shape=(), dtype=float3...</td>\n",
       "      <td>HTC-1-M7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            location  \\\n",
       "0  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "1  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "2  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "3  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "4  D:\\Study\\Capstone\\cameraDetection\\sp-society-c...   \n",
       "\n",
       "                                               image    camera  class  \n",
       "0  (((tf.Tensor(0.47058824, shape=(), dtype=float...  HTC-1-M7      0  \n",
       "1  (((tf.Tensor(0.6745098, shape=(), dtype=float3...  HTC-1-M7      0  \n",
       "2  (((tf.Tensor(0.59607846, shape=(), dtype=float...  HTC-1-M7      0  \n",
       "3  (((tf.Tensor(0.41568628, shape=(), dtype=float...  HTC-1-M7      0  \n",
       "4  (((tf.Tensor(0.5764706, shape=(), dtype=float3...  HTC-1-M7      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['class'] = df1['camera'].apply(lambda x:class_dict[x])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['image_array'] = df1['image'].apply(lambda x:x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(df1['image_array'], df1['class'].values,test_size=.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def reshape_input(Xtrain):\n",
    "    #Xtrain = np.stack(Xtrain.values) #convert a pandas series of arrays into one single array\n",
    "    input_cols = Xtrain.shape[1]*Xtrain.shape[2]*Xtrain.shape[3]\n",
    "    Xtrain = np.reshape(Xtrain,(Xtrain.shape[0],input_cols)) #flatten the data to single set of neurons\n",
    "    return Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "def reshape_target(Ytrain):\n",
    "    Ytrain = to_categorical(Ytrain,num_classes=10)\n",
    "    return Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1842, 192, 192, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(Xtrain.values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1842,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 110592)\n"
     ]
    }
   ],
   "source": [
    "trainingsize = 6000\n",
    "batchsize = 64\n",
    "iteration = 1\n",
    "itersize = trainingsize/batchsize\n",
    "for batch in datagen.flow(np.stack(Xtrain.values),Ytrain,batch_size= batchsize):\n",
    "    batch_x = reshape_input(batch[0])\n",
    "    batch_y = reshape_target(batch[1])\n",
    "    print(batch_x.shape)\n",
    "    break\n",
    "    \n",
    "    #model.fit_generator(batch,validation_split=.3,epochs=40)\n",
    "    #iteration+=1\n",
    "    #if(iteration >itersize )\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
